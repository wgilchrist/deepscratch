{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepscratch.initialisers\n",
      "deepscratch.activations\n",
      "deepscratch.dataset.vision\n",
      "deepscratch.dataset.base\n",
      "deepscratch.optimisers\n",
      "deepscratch.losses\n",
      "deepscratch.transformations\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import deepscratch\n",
    "from abc import ABC, abstractmethod\n",
    "import matplotlib.pyplot as plt\n",
    "from deepscratch.initialisers import Gaussian, Zeros\n",
    "from deepscratch.typing import PyTree\n",
    "from deepscratch.activations import ReLU, Softmax, Activation\n",
    "from deepscratch.dataset.vision import MNISTDataset\n",
    "from deepscratch.dataset.base import DataLoader\n",
    "from deepscratch.optimisers import SGD, Adam\n",
    "from deepscratch.losses import CrossEntropy, Accuracy\n",
    "from deepscratch.transformations import Reshape\n",
    "\n",
    "from functools import partial, wraps\n",
    "from typing import Tuple\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(ABC):\n",
    "\n",
    "    def __init__(self):\n",
    "        self._w = None\n",
    "        self.initialise()\n",
    "\n",
    "        self.forward = jax.jit(self.forward)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def initialise(self) -> PyTree[jnp.array]:\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    @abstractmethod\n",
    "    def forward(self, x, w):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-02-19 13:21:09,581:jax._src.xla_bridge:1018: Platform 'METAL' is experimental and not all JAX functionality may be correctly supported!\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1739971269.581463 8747963 mps_client.cc:510] WARNING: JAX Apple GPU support is experimental and not all JAX functionality is correctly supported!\n",
      "I0000 00:00:1739971269.600857 8747963 service.cc:145] XLA service 0x127059360 initialized for platform METAL (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1739971269.600865 8747963 service.cc:153]   StreamExecutor device (0): Metal, <undefined>\n",
      "I0000 00:00:1739971269.601808 8747963 mps_client.cc:406] Using Simple allocator.\n",
      "I0000 00:00:1739971269.601814 8747963 mps_client.cc:384] XLA backend will use up to 11452776448 bytes on device 0 for SimpleAllocator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M3\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class LinearBlock(Block):\n",
    "    def __init__(self, input_len: int, output_len: int, weight_init_method=Gaussian(0,1e-3), bias_init_method=Zeros()):\n",
    "        self.input_len = input_len\n",
    "        self.output_len = output_len\n",
    "        self.weight_init_method = weight_init_method\n",
    "        self.bias_init_method = bias_init_method\n",
    "        super().__init__()\n",
    "\n",
    "    def initialise(self) -> PyTree[jnp.array]:\n",
    "        w = {}\n",
    "        w[\"w_yx\"] = self.weight_init_method((self.input_len, self.output_len))\n",
    "        w[\"b_y\"] = self.bias_init_method((self.output_len,))\n",
    "        return w\n",
    "    \n",
    "    @staticmethod\n",
    "    @jax.jit\n",
    "    def forward(x, w):\n",
    "        return x @ w[\"w_yx\"] + w[\"b_y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential: \n",
    "    def __init__(self, layers: list[Block, Activation]):\n",
    "        self._layers = layers\n",
    "        self._pure_forward = jax.jit(partial(self._pure_forward, layers=self._layers))\n",
    "        self.trace_shape = partial(self.trace_shape, layers=self._layers)\n",
    "        self.initialise()\n",
    "\n",
    "    @property\n",
    "    def layers(self):\n",
    "        return self._layers\n",
    "    \n",
    "    def n_params(self):\n",
    "        leaves = jax.tree_util.tree_leaves(self.w)\n",
    "        total_elements = sum(leaf.size for leaf in leaves if hasattr(leaf, \"size\"))\n",
    "        return total_elements\n",
    "    \n",
    "    def forward(self, x: jnp.array) -> jnp.array:\n",
    "        return self._pure_forward(x, self.w)\n",
    "    \n",
    "    def trace_shape(self, shape: Tuple[int], layers) -> str:\n",
    "        print(f\"Input: shape: {shape}\")\n",
    "        z = jnp.ones(shape)\n",
    "        i=0\n",
    "        for layer in layers:\n",
    "            if isinstance(layer, Block):\n",
    "                z = layer.forward(z, self.w[i])\n",
    "                i += 1\n",
    "            else:\n",
    "                z = layer.forward(z)\n",
    "            print(f\"Layer: {layer}\\t shape: {z.shape}\")\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    @staticmethod\n",
    "    def _pure_forward(x: jnp.array, w: PyTree[jnp.array], layers) -> jnp.array:\n",
    "        z = x\n",
    "        i=0\n",
    "        for layer in layers:\n",
    "            if isinstance(layer, Block):\n",
    "                z = layer.forward(z, w[i])\n",
    "                i += 1\n",
    "            else:\n",
    "                z = layer.forward(z)\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    def initialise(self):\n",
    "        self.w = [\n",
    "            layer.initialise() for layer in self.layers \n",
    "            if isinstance(layer, Block)\n",
    "        ]\n",
    "\n",
    "    def train(self, data, loss_func, optimiser_cls, lr=1e-3, epochs=4, device=\"cpu\"):\n",
    "\n",
    "        self.initialise()\n",
    "        w0 = self.w\n",
    "        \n",
    "        @jax.jit\n",
    "        def objective(w, data):\n",
    "            X, Y = data\n",
    "            return loss_func.forward(self._pure_forward(X, w), Y)\n",
    "        \n",
    "        self.stepper = optimiser_cls(objective, lr, device=device)\n",
    "        optimiser = SGD(self.stepper, data, epochs=epochs)\n",
    "        self.w = optimiser.compute(w0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self(X, *self.w)\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "        y_est = self.predict(X)\n",
    "        return (y_est.argmax(axis=1) == y.argmax(axis=1)).sum() / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resconnect(block_cls: Type):\n",
    "\n",
    "    ResClass = type(\"Res\"+block_cls.__name__, (block_cls,), {})\n",
    "    ResClass.__module__ = block_cls.__module__\n",
    "\n",
    "    @staticmethod\n",
    "    @wraps(block_cls.forward)\n",
    "    def new_forward(x: jnp.array, w: PyTree[jnp.array]):\n",
    "        return x + block_cls.forward(x, w)\n",
    "    \n",
    "    ResClass.forward = new_forward\n",
    "    return ResClass\n",
    "\n",
    "ResLinearBlock = resconnect(LinearBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[1., 1.]], dtype=float32), Array([[2., 2.]], dtype=float32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = LinearBlock(10,10)\n",
    "reslinear = ResLinearBlock(10, 10)\n",
    "\n",
    "x = jnp.array([[1,1]])\n",
    "w = {\"w_yx\": jnp.array([[1,0],[0,1]], dtype=\"float32\"), \"b_y\": jnp.array([0,0], dtype=\"float32\")}\n",
    "\n",
    "linear.forward(x,w), reslinear.forward(x,w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
