{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepscratch.dataset.base\n",
      "deepscratch.dataset.sequence\n",
      "deepscratch.models.sequence.tokeniser\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/willgilchrist/dev/mlvenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepscratch.models.sequence.embeddings\n",
      "deepscratch.models.base\n",
      "deepscratch.initialisers\n",
      "deepscratch.activations\n",
      "deepscratch.dataset.vision\n",
      "deepscratch.optimisers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-02-22 14:31:35,012:jax._src.xla_bridge:1018: Platform 'METAL' is experimental and not all JAX functionality may be correctly supported!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepscratch.losses\n",
      "deepscratch.transformations\n",
      "Metal device set to: Apple M3\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "deepscratch.normalisers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1740234695.012998 9763662 mps_client.cc:510] WARNING: JAX Apple GPU support is experimental and not all JAX functionality is correctly supported!\n",
      "I0000 00:00:1740234695.025963 9763662 service.cc:145] XLA service 0x15a0e9f30 initialized for platform METAL (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1740234695.025971 9763662 service.cc:153]   StreamExecutor device (0): Metal, <undefined>\n",
      "I0000 00:00:1740234695.026901 9763662 mps_client.cc:406] Using Simple allocator.\n",
      "I0000 00:00:1740234695.026908 9763662 mps_client.cc:384] XLA backend will use up to 11452776448 bytes on device 0 for SimpleAllocator.\n"
     ]
    }
   ],
   "source": [
    "from deepscratch.dataset.base import DataLoader\n",
    "from deepscratch.dataset.sequence import SequenceDataset\n",
    "from deepscratch.models.base import Block, Sequential, LinearBlock\n",
    "from deepscratch.models.sequence.tokeniser import HFTokeniser\n",
    "from deepscratch.models.sequence.embeddings import LSA, OHE, HFEmbedder\n",
    "from deepscratch.initialisers import Orthonormal, Zeros, Xavier\n",
    "from deepscratch.activations import Activation, Sigmoid, Tanh, Softmax, ReLU, LinearActivation\n",
    "from deepscratch.losses import RMSE, CrossEntropy\n",
    "from deepscratch.optimisers import Adam\n",
    "from deepscratch.normalisers import BatchNorm\n",
    "\n",
    "import random   \n",
    "\n",
    "from functools import partial\n",
    "import jax.numpy as jnp\n",
    "from jax import lax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser = HFTokeniser('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/willgilchrist/dev/deeplearning/data/books/timemachine.txt\", \"rt\") as f:\n",
    "    embedder = OHE(f, tokeniser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../__deepscratchcache__/thetimemachine.pkl\", \"rb\") as f:\n",
    "    embedder = LSA.from_cache(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of FlaxBertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: {('pooler', 'dense', 'kernel'), ('pooler', 'dense', 'bias')}\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "embedder = HFEmbedder('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/willgilchrist/dev/deeplearning/data/books/timemachine.txt\", \"rt\") as f:\n",
    "    ds = SequenceDataset(f, 10, 10, tokeniser, embedder)\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "dl = DataLoader(ds, BATCH_SIZE, shuffle=True, num_workers=16, drop_last=True, iobound=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNEncoder(Block):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size: int,\n",
    "            hidden_size: int,\n",
    "            activation: Activation = Tanh(),\n",
    "            input_weight_init_method=Xavier(),\n",
    "            recur_weight_init_method=Orthonormal(),\n",
    "            bias_init_method=Zeros()\n",
    "        ):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.input_weight_init_method = input_weight_init_method\n",
    "        self.recur_weight_init_method = recur_weight_init_method\n",
    "        self.bias_init_method = bias_init_method\n",
    "\n",
    "        self.forward = partial(\n",
    "            self.forward,\n",
    "            activation=self.activation.forward,\n",
    "            hidden_size = self.hidden_size\n",
    "        )\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "    def initialise(self):\n",
    "        w = {}\n",
    "        w[\"w_hx\"] = self.input_weight_init_method((self.input_size, self.hidden_size))\n",
    "        w[\"w_hh\"] = self.recur_weight_init_method((self.hidden_size, self.hidden_size))\n",
    "        w[\"b_h\"] = self.bias_init_method((self.hidden_size,))\n",
    "\n",
    "        return w\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(x, w, activation, hidden_size):\n",
    "        h = jnp.zeros((x.shape[0], hidden_size))\n",
    "\n",
    "        step = lambda t, h : activation(x[...,t,:] @ w[\"w_hx\"] + h @ w[\"w_hh\"] + w[\"b_h\"])\n",
    "        h = lax.fori_loop(0, x.shape[-2], step, h) # \n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNDecoder(Block):\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_steps: int,\n",
    "            input_size: int,\n",
    "            output_size: int,\n",
    "            hidden_size: int,\n",
    "\n",
    "            hidden_activation: Activation = Tanh(),\n",
    "            output_activation: Activation = LinearActivation(),\n",
    "    \n",
    "            input_weight_init_method=Xavier(),\n",
    "            recur_weight_init_method=Orthonormal(),\n",
    "            bias_init_method=Zeros()\n",
    "        ):\n",
    "        self.n_steps = n_steps\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.hidden_activation = hidden_activation\n",
    "        self.output_activation = output_activation\n",
    "        \n",
    "        self.input_weight_init_method = input_weight_init_method\n",
    "        self.recur_weight_init_method = recur_weight_init_method\n",
    "        self.bias_init_method = bias_init_method\n",
    "\n",
    "        self.forward = partial(\n",
    "            self.forward,\n",
    "            hidden_activation=self.hidden_activation.forward,\n",
    "            output_activation=self.output_activation.forward,\n",
    "            n_steps=self.n_steps,\n",
    "            hidden_size = self.hidden_size,\n",
    "            output_size = self.output_size\n",
    "        )\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "    def initialise(self):\n",
    "        w = {}\n",
    "        # Hidden state weights\n",
    "        w[\"w_hx\"] = self.input_weight_init_method((self.input_size, self.hidden_size))\n",
    "        w[\"w_hh\"] = self.recur_weight_init_method((self.hidden_size, self.hidden_size))\n",
    "        w[\"w_hy\"] = self.input_weight_init_method((self.output_size, self.hidden_size))\n",
    "        w[\"b_h\"] = self.bias_init_method((self.hidden_size,))\n",
    "\n",
    "        # Output weights\n",
    "        w[\"w_yh\"] = self.recur_weight_init_method((self.hidden_size, self.output_size))\n",
    "        w[\"b_y\"] = self.bias_init_method((self.output_size,))\n",
    "\n",
    "        return w\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(x, w, hidden_activation, output_activation, n_steps, hidden_size, output_size):\n",
    "        h = jnp.zeros((x.shape[0], hidden_size))\n",
    "        yt = jnp.zeros((x.shape[0], output_size))\n",
    "        y = []\n",
    "        for t in range(n_steps):\n",
    "            h = hidden_activation(x @ w[\"w_hx\"] + h @ w[\"w_hh\"] + yt @ w[\"w_hy\"] + w[\"b_h\"])\n",
    "            yt = output_activation(h @ w[\"w_yh\"] + w[\"b_y\"])\n",
    "            y.append(yt)\n",
    "        \n",
    "        y = jnp.stack(y, axis=-2)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((256, 10, 768), (256, 10, 768))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dl))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_hidden_size = decoder_hidden_size = 50\n",
    "\n",
    "ann = Sequential([\n",
    "    RNNEncoder(x.shape[-1], encoder_hidden_size),\n",
    "    RNNDecoder(y.shape[-2], encoder_hidden_size, y.shape[-1], decoder_hidden_size, output_activation=LinearActivation())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40480, 123568)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds), ann.n_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.initialise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 632\tStep: 1.7E-03\tLoss: 4.127E-01\n"
     ]
    }
   ],
   "source": [
    "ann.train(\n",
    "    dl,\n",
    "    RMSE(),\n",
    "    Adam,\n",
    "    lr=1e-4,\n",
    "    epochs=1,\n",
    "    device=\"METAL\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/willgilchrist/dev/deeplearning/data/books/timemachine.txt\", \"rt\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "corpus = jnp.unique(tokeniser.tokenise(text))\n",
    "corpus_embeddings = embedder.embed(corpus)\n",
    "\n",
    "def to_words(arr: jnp.array) -> list[str]:\n",
    "    words = []\n",
    "    for t in range(arr.shape[-2]):\n",
    "        if isinstance(embedder, LSA):\n",
    "            euc_dist = ((embedder.embeddings - arr[...,t,:]) ** 2).sum(axis=-1)\n",
    "            i = euc_dist.argmin()\n",
    "            words.append(embedder.idx_to_token[i.item()])\n",
    "\n",
    "        elif isinstance(embedder, OHE):\n",
    "            i = arr[...,t,:].argmax()\n",
    "            words.append(embedder.idx_to_token[i.item()])\n",
    "\n",
    "        elif isinstance(embedder, HFEmbedder):\n",
    "            distances = ((corpus_embeddings - arr[...,t,:]) ** 2).sum(axis=1)\n",
    "            min_idx = distances.argmin()\n",
    "            min_token = corpus[min_idx]\n",
    "            words.append(tokeniser.idx_to_token[min_token.item()])\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: them with the lever ##s , and began to scramble\n",
      "Predicted Passage: bird with with with with with with with with with\n"
     ]
    }
   ],
   "source": [
    "# Take one sample\n",
    "i = random.randint(0, len(dl))\n",
    "for _, (x,y) in zip(range(i), dl):\n",
    "    pass\n",
    "\n",
    "x0, y0 = x[jnp.array([0])], y[jnp.array([0])] \n",
    "y_est = ann.forward(x)\n",
    "y0_est = y_est[jnp.array([0])]\n",
    "\n",
    "print(f\"Input: {\" \".join(to_words(x0))}\\nPredicted Passage: {\" \".join(to_words(y0_est))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: first impenetrably dark to me\n",
      "Actual: i entered it groping for\n",
      "Predicted: the the the i i\n"
     ]
    }
   ],
   "source": [
    "i = random.randint(0, len(ds))\n",
    "x, y = ds[i]\n",
    "x, y = jnp.expand_dims(x, axis=0), jnp.expand_dims(y, axis=0)   # add batch dim\n",
    "y_est = ann.forward(x)\n",
    "print(f\"Start: {\" \".join(to_words(x))}\\nActual: {\" \".join(to_words(y))}\\nPredicted: {\" \".join(to_words(y_est))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take one sample\n",
    "i = random.randint(0, len(ds))\n",
    "x, y = ds[i]\n",
    "x, y = jnp.expand_dims(x, axis=0), jnp.expand_dims(y, axis=0)   # add batch dim\n",
    "\n",
    "# encode x to a context vector\n",
    "w_emb, w_enc, w_dec = ann.w\n",
    "embed_fc, encoder, _ = ann.layers\n",
    "x_embed = embed_fc.forward(x, w_emb)\n",
    "context = encoder.forward(x_embed, w_enc)\n",
    "\n",
    "# New decoder that forecasts 50 steps ahead\n",
    "decoder = RNNDecoder(50, encoder_hidden_size, y.shape[-1], decoder_hidden_size, output_activation=Softmax())\n",
    "y_est = decoder.forward(context, w_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Passage:\n",
      "the the the the i i the the i the the the the the i i i i i i i i i i i i i i i i i i i i i i i suffering i i i i i i i i i i i i\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted Passage:\\n{\" \".join(to_words(y_est))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMBlock(Block):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size: int,\n",
    "            hidden_size: int,\n",
    "            activation=Tanh(),\n",
    "            gate_activation=Sigmoid(),\n",
    "            input_weight_init_method=Xavier(),\n",
    "            recur_weight_init_method=Orthonormal(),\n",
    "            bias_init_method=Zeros()\n",
    "        ):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.activation = activation\n",
    "        self.gate_activation = gate_activation\n",
    "        \n",
    "        self.input_weight_init_method = input_weight_init_method\n",
    "        self.recur_weight_init_method = recur_weight_init_method\n",
    "        self.bias_init_method = bias_init_method\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "    def initialise(self):\n",
    "        self.w = {}\n",
    "        self.w[\"w_hx\"] = self.input_weight_init_method((self.input_size, self.hidden_size * 4))\n",
    "        self.w[\"w_hh\"] = self.recur_weight_init_method((self.hidden_size, self.hidden_size * 4))\n",
    "        self.w[\"b\"] = self.bias_init_method((self.hidden_size * 4,))\n",
    "    \n",
    "    def __call__(self, x, h, c):\n",
    "        gates = x @ self.w[\"w_x\"] + h @ self.w[\"w_h\"] + self.w[\"b\"]\n",
    "        i, f, g, o = jnp.split(gates, 4, axis=-1)\n",
    "        i = self.gate_activation(i)\n",
    "        f = self.gate_activation(f)\n",
    "        g = self.activation(g)\n",
    "        o = self.gate_activation(o)\n",
    "        c_next = f * c + i * g\n",
    "        h_next = o * self.activation(c_next)\n",
    "        return h_next, c_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionBlock(Block):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embed_dim: int,\n",
    "            num_heads: int,\n",
    "            activation,\n",
    "            weight_init_method = Xavier(),\n",
    "            bias_init_method = Zeros()\n",
    "        ):\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.weight_init_method = weight_init_method\n",
    "        self.bias_init_method = bias_init_method\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "    def initialise(self):\n",
    "        self.w = {}\n",
    "        self.w[\"w_q\"] = self.weight_init_method((self.embed_dim, self.embed_dim))\n",
    "        self.w[\"w_k\"] = self.weight_init_method((self.embed_dim, self.embed_dim))\n",
    "        self.w[\"w_v\"] = self.weight_init_method((self.embed_dim, self.embed_dim))\n",
    "        self.w[\"w_o\"] = self.weight_init_method((self.embed_dim, self.embed_dim))\n",
    "        self.w[\"b_o\"] = self.bias_init_method((self.embed_dim,))\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        q = x @ self.w[\"w_q\"]\n",
    "        k = x @ self.w[\"w_k\"]\n",
    "        v = x @ self.w[\"w_v\"]\n",
    "        \n",
    "        q = q.reshape(q.shape[0], -1, self.num_heads, self.head_dim).transpose(0, 2, 1, 3)\n",
    "        k = k.reshape(k.shape[0], -1, self.num_heads, self.head_dim).transpose(0, 2, 1, 3)\n",
    "        v = v.reshape(v.shape[0], -1, self.num_heads, self.head_dim).transpose(0, 2, 1, 3)\n",
    "        \n",
    "        attn_scores = jnp.einsum('bhid,bhjd->bhij', q, k) / jnp.sqrt(self.head_dim)\n",
    "        attn_weights = Softmax()(attn_scores, axis=-1)\n",
    "        attn_output = jnp.einsum('bhij,bhjd->bhid', attn_weights, v)\n",
    "        \n",
    "        attn_output = attn_output.transpose(0, 2, 1, 3).reshape(x.shape[0], -1, self.embed_dim)\n",
    "        return attn_output @ self.w[\"w_o\"] + self.w[\"b_o\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Block):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embed_dim: int,\n",
    "            num_heads: int,\n",
    "            feedforward_dim: int,\n",
    "            activation, \n",
    "            weight_init_method = Xavier(),\n",
    "            bias_init_method = Zeros()\n",
    "        ):\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.feedforward_dim = feedforward_dim\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.weight_init_method = weight_init_method\n",
    "        self.bias_init_method = bias_init_method\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "    def initialise(self):\n",
    "        self.attention = SelfAttentionBlock(\n",
    "            self.embed_dim, self.num_heads, self.activation, self.weight_init_method, self.bias_init_method, self.key\n",
    "        )\n",
    "        \n",
    "        self.w = {}\n",
    "        self.w[\"w_ff1\"] = self.weight_init_method((self.embed_dim, self.feedforward_dim))\n",
    "        self.w[\"b_ff1\"] = self.bias_init_method((self.feedforward_dim,))\n",
    "        self.w[\"w_ff2\"] = self.weight_init_method((self.feedforward_dim, self.embed_dim))\n",
    "        self.w[\"b_ff2\"] = self.bias_init_method((self.embed_dim,))\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        attn_out = self.attention(x) + x\n",
    "        ff_out = self.activation(attn_out @ self.w[\"w_ff1\"] + self.w[\"b_ff1\"])\n",
    "        ff_out = ff_out @ self.w[\"w_ff2\"] + self.w[\"b_ff2\"]\n",
    "        return ff_out + attn_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
